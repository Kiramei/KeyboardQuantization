# 指导文件
## 知识蒸馏
### 定义
知识蒸馏（Knowledge Distillation）是一种机器学习中的技术，用于将一个复杂的模型的知识转移到一个简化的模型中。这个过程可以帮助简化模型，减少计算资源的需求，并提高模型的推断速度。

在知识蒸馏中，通常会有两个模型参与：
* 教师模型（Teacher Model）：教师模型是一个复杂的模型，通常具有较大的容量和表达能力。它在训练数据上进行训练，并具有较高的性能。
* 学生模型（Student Model）：学生模型是一个简化的模型，通常具有较小的容量和表达能力。它的目标是从教师模型中学习，并尽可能地复制教师模型的行为和性能。

 知识蒸馏的主要思想是通过将教师模型的知识传授给学生模型来提高学生模型的性能。这可以通过以下方法之一来实现：
* 软标签（Soft Labels）：教师模型不仅输出预测的类别标签，还输出一组概率分布，称为软标签。学生模型通过尝试匹配这些软标签来学习教师模型的知识。
* 知识传递（Knowledge Transfer）：除了软标签外，教师模型的其他中间表示或隐藏层的输出也可以用作学生模型的目标。学生模型通过尝试复制教师模型的中间表示来学习知识。
* 温度调节（Temperature Scaling）：通过调节教师模型输出的温度，可以控制软标签的平滑程度。较高的温度值会使概率分布更平滑，提供更多的信息给学生模型。

通过使用知识蒸馏技术，学生模型能够从教师模型中受益，获得更好的泛化能力和性能。这对于在计算资源受限的环境中部署模型或在移动设备上运行模型非常有用。

需要注意的是，知识蒸馏是一个广泛的研究领域，有许多不同的方法和变体。以上是一个简单的概述，涵盖了其中的一些基本概念和思想。

### DistillModel

1. 使用DistillModel,先创建DistillModel对象：实例化DistillModel类，并传入以下参数：

   * source_data：原始数据，作为模型的输入数据。
   * temperature：温度参数，用于计算教师模型的软标签，默认为5。
   * lr：学习率，用于优化器的学习率，默认为0.001。
   * momentum：动量参数，用于SGD优化器的动量，默认为0.9。
    * 定义教师模型和学生模型：在DistillModel类的构造函数中，定义了教师模型和学生模型。这里使用了resnet18作为模型的基础结构，你也可以根据需要选择其他模型。

2. 定义损失函数和优化器：在构造函数中，定义了交叉熵损失函数作为损失函数，并使用Adam优化器进行参数优化。如果你希望使用SGD优化器，可以注释掉Adam优化器的部分，取消注释SGD优化器的部分。

3. 训练模型：调用train方法进行模型训练。在训练过程中，首先通过教师模型和学生模型分别对输入数据进行前向传播，然后计算教师模型的软标签。接下来，计算损失函数，包括学生模型对硬标签（hard_labels）和软标签（soft_labels）的损失。最后，进行反向传播和优化，更新学生模型的参数。

4. 请注意，source_data和hard_labels参数是输入的数据集，其他的为超参数。

## 神经网络量化
### 定义
神经网络量化是一种通过减少权重表示所需比特数来压缩原始网络的方法。在传统的深度神经网络（DNN）中，权重通常以32位浮点数的形式存储。量化法则是将权重表示为更低精度的形式，例如16位、8位、4位甚至1位。其中，8位参数量化已经能够在损失少量准确率的情况下实现显著的加速，因此在这里采用了8位参数量化。

神经网络量化通常包括以下三个过程：

* 修剪小权重的连接：通过设置阈值来剪枝或删除网络中较小的权重连接。这样可以减少网络的稀疏性，从而减少后续量化步骤的计算量。

* 使用权重共享来量化权重：通过对权重进行聚类或分组，并为每个聚类分配一个共享的权重值。这样可以减少权重的唯一表示，从而降低存储和计算成本。

* 应用哈夫曼编码：对量化后的权重和码本应用哈夫曼编码。哈夫曼编码是一种可变长度编码方法，通过为常见权重分配较短的编码，为罕见权重分配较长的编码，从而进一步减少存储空间。

整个量化过程可以描述为以下步骤：

1. 原始网络：使用32位浮点数表示的原始神经网络。

2. 训练连接：通过训练过程修剪掉小权重的连接，减少网络的稀疏性。

3. 剪枝连接：修剪后的网络，删除了较小的权重连接。

4. 训练权重：对修剪后的网络进行权重训练。

5. 权重聚类：对训练后的权重进行聚类，将相似的权重分到同一个聚类中。

6. 生成码本：为每个聚类生成一个共享的权重值，作为码本。

7. 权重量化：使用码本对权重进行量化，将权重映射为码本中的值。

8. 重新训练码本：对量化后的权重和码本进行重新训练，以优化量化结果。

9. 权重编码：将量化后的权重使用哈夫曼编码进行编码，以进一步减少存储空间。

最终，通过神经网络量化，可以在保持相似准确率的情况下大幅度减少模型的大小，从而实现更高效的推理和部署。具体来说，这种量化方法可以实现35倍到49倍的参数量减少。
### mount.py
* def quantize_model(model):  传入参数为神经网络，输出量化后的网络。
* def dequantize_model(model): 传入参数为计算后的网络，输出解量化的网络。